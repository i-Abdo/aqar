# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# Allow all crawlers to access all content
User-agent: *
Disallow: /admin
Disallow: /dashboard
Disallow: /login
Disallow: /signup

Sitemap: /sitemap.xml
